{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Four qpAdm tests:\n",
    "\n",
    "Extract relevant information\n",
    "\n",
    "Turn to xlsx, filtered format.\n",
    "\n",
    "Analysis:\n",
    "1. (ANCASN, ANCASN; PDEAS+ANCASN) -- present-day mixture of past ANCASN?\n",
    "2. (SIB, ANCASN; PDEAS) -- PDEAS have more NAsn ancestry than ancient SASN??\n",
    "3. (AMER, ANCASN+SIB; AMER) -- Surui/Karitiana affinities?\n",
    "4. (EUR+Natufian, ANCASN; PDEAS+ANCASN) -- BE/ANE/WHG influences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##CASE B: (SIB, ANCASN; PDEAS) -- PDEAS have more NAsn ancestry than ancient SASN??\n",
    "##EXTRACT RELEVANT DATA FROM QPADM\n",
    "import projmodules as pm\n",
    "\n",
    "pD=\"/mnt/solexa/mel_yang/2.2_neolithic/qpAdm/CaseB/\"\n",
    "fh=\"UPA_all8\"\n",
    "baseoutgroup=[\"Yoruba\",\"Ju_hoan_North\",\"Dinka\",\"Mbuti\",\"UstIshim\"] ##0\n",
    "myoutgroups=[\"Kostenki14\",\"Vestonice16\",\"Tianyuan\",\"Longlin\",\"Onge\",\"Papuan\"] #1\n",
    "sib=[\"Altaian\",\"Eskimo_Sireniki\",\"Even\",\"Itelman\",\"Mongola\",\"Tubalar\",\n",
    "     \"Ulchi\",\"Yakut\",\"Kolyma_River\"]\n",
    "\n",
    "eas=[\"Ami\",\"Atayal\",\"Dai\",\"Daur\",\"Han\",\"Hezhen\",\"Japanese\",\"Korean\",\"Kinh\",\n",
    "     \"Lahu\",\"Miao\",\"Naxi\",\"Oroqen\",\"She\",\"Tujia\",\"Yi\"]\n",
    "\n",
    "ancasn=[\"Tianyuan\",'Longlin','Longlin_com','Xinyi','Xinyi_other','Daxi',\n",
    "        'LiangDaoChineseNeolithic','Boisman_MN','BoshanChineseNeolithic',\n",
    "        'Bbdong',] #'Linzi','HDYM1','HQSDW','Zongri','Pukagongma']\n",
    "\n",
    "eup=[\"GoyetQ116-1\",\"Vestonice16\",\"Yana_old\",\"Yana_old2\",\n",
    "     \"Malta1\",'AfontovaGora3',\"ElMiron\",\"Villabruna\",\"Satsurblia\",\"Karelia\",\n",
    "     \"Loschbour\",\"LaBrana1\",\"Hungarian.KO1\",\"Stuttgart\",\"French\"]\n",
    "\n",
    "\n",
    "s1s=sib\n",
    "s2s=ancasn\n",
    "targets=ancasn+eas\n",
    "newname,myoutind = ('adm_SIB_ANCASN_PDEASANCASN',4) \n",
    "alldata = \"\"\n",
    "for ind0, p2 in enumerate(s1s):\n",
    "    if p2 in myoutgroups: continue\n",
    "    for ind2,myind2 in enumerate(targets):\n",
    "        if p2==myind2: continue\n",
    "        if myind2 in myoutgroups: continue\n",
    "        for ind1,myind1 in enumerate(s2s):\n",
    "            if myind1 in myoutgroups: continue\n",
    "            if myind1==myind2 or p2 == myind1 or p2==myind2: continue\n",
    "\n",
    "            s1,s2,target = (p2,myind1,myind2)\n",
    "            #print s1,s2,target\n",
    "            subset = 'X_%s_S1_%s_S2_%s_out%i' % (target,s1,s2,myoutind)\n",
    "            myinfo = pm.wave_extractAdmdata(pD,fh,subset,(s1,s2),target)\n",
    "            #print myinfo\n",
    "            if myinfo == 'NOFILE': continue\n",
    "            comboswanted = ['00','01','10']\n",
    "            rankswanted = ['1']\n",
    "            ranksprint = '\\t'.join([str(myinfo['f4rank'][i]) for i in rankswanted])\n",
    "            pvalsprint = '\\t'.join(['%s\\t%s\\t%s\\t%s' % tuple(myinfo['admix'][i]+myinfo['nestp'][i]) if i in myinfo['nestp'] else '%s\\t%s\\t%s\\tNA' % tuple(myinfo['admix'][i]) for i in comboswanted])\n",
    "            allprint = ranksprint+'\\t'+pvalsprint\n",
    "            header = 'S1\\tS2\\tTarget\\trank1\\t%s_p\\t%s_f1\\t%s_f2\\t%s_pnest\\t%s_p\\t%s_f1\\t%s_f2\\t%s_pnest\\t%s_p\\t%s_f1\\t%s_f2\\t%s_pnest\\tse1\\tse2\\n' % tuple(comboswanted[0:1]*4+comboswanted[1:2]*4+comboswanted[2:3]*4)\n",
    "    \n",
    "            alldata+='\\t'.join([s1,s2,target])+'\\t'+allprint+'\\t'+'\\t'.join(myinfo['se'])+'\\n'\n",
    "      \n",
    "newfile = open(pD+fh+'.'+newname+'.out'+str(myoutind)+'.tab','w')\n",
    "newfile.writelines(header+alldata)\n",
    "newfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##CASE A: (ANCASN, ANCASN; PDEAS+ANCASN) -- present-day mixture of past ANCASN?\n",
    "##EXTRACT RELEVANT DATA FROM QPADM\n",
    "import projmodules as pm\n",
    "\n",
    "pD=\"/mnt/solexa/mel_yang/2.2_neolithic/qpAdm/CaseA/\"\n",
    "fh=\"UPA_all8\"\n",
    "baseoutgroup=[\"Yoruba\",\"Ju_hoan_North\",\"Dinka\",\"Mbuti\",\"UstIshim\"] ##0\n",
    "myoutgroups=[\"Kostenki14\",\"Vestonice16\",\"Tianyuan\",\"Longlin\",\"Onge\",\"Papuan\"] #1\n",
    "sib=[\"Altaian\",\"Eskimo_Sireniki\",\"Even\",\"Itelman\",\"Mongola\",\"Tubalar\",\n",
    "     \"Ulchi\",\"Yakut\",\"Kolyma_River\"]\n",
    "\n",
    "eas=[\"Ami\",\"Atayal\",\"Dai\",\"Daur\",\"Han\",\"Hezhen\",\"Japanese\",\"Korean\",\"Kinh\",\n",
    "     \"Lahu\",\"Miao\",\"Naxi\",\"Oroqen\",\"She\",\"Tujia\",\"Yi\"]\n",
    "\n",
    "ancasn=[\"Tianyuan\",'Longlin','Longlin_com','Xinyi','Xinyi_other','Daxi',\n",
    "        'LiangDaoChineseNeolithic','Boisman_MN','BoshanChineseNeolithic',\n",
    "        'Bbdong','Linzi','HDYM1','HQSDW','Zongri','Pukagongma']\n",
    "\n",
    "eup=[\"GoyetQ116-1\",\"Vestonice16\",\"Yana_old\",\"Yana_old2\",\n",
    "     \"Malta1\",'AfontovaGora3',\"ElMiron\",\"Villabruna\",\"Satsurblia\",\"Karelia\",\n",
    "     \"Loschbour\",\"LaBrana1\",\"Hungarian.KO1\",\"Stuttgart\",\"French\"]\n",
    "\n",
    "\n",
    "s1s=ancasn\n",
    "s2s=ancasn\n",
    "targets=eas\n",
    "newname,myoutind = ('adm_ANCASN_ANCASN_PDANCASN',4) \n",
    "alldata = \"\"\n",
    "for ind0, p2 in enumerate(s1s):\n",
    "    if p2 in myoutgroups: continue\n",
    "    for ind2,myind2 in enumerate(targets):\n",
    "        if p2==myind2: continue\n",
    "        if myind2 in myoutgroups: continue\n",
    "        for ind1,myind1 in enumerate(s2s):\n",
    "            if myind1 in myoutgroups: continue\n",
    "            if myind1==myind2 or p2 == myind1 or p2==myind2: continue\n",
    "\n",
    "            s1,s2,target = (myind1,p2,myind2)\n",
    "            #print s1,s2,target\n",
    "            subset = 'X_%s_S1_%s_S2_%s_out%i' % (target,s1,s2,myoutind)\n",
    "            myinfo = pm.wave_extractAdmdata(pD,fh,subset,(s1,s2),target)\n",
    "            #print myinfo\n",
    "            if myinfo == 'NOFILE': continue\n",
    "            comboswanted = ['00','01','10']\n",
    "            rankswanted = ['1']\n",
    "            ranksprint = '\\t'.join([str(myinfo['f4rank'][i]) for i in rankswanted])\n",
    "            pvalsprint = '\\t'.join(['%s\\t%s\\t%s\\t%s' % tuple(myinfo['admix'][i]+myinfo['nestp'][i]) if i in myinfo['nestp'] else '%s\\t%s\\t%s\\tNA' % tuple(myinfo['admix'][i]) for i in comboswanted])\n",
    "            allprint = ranksprint+'\\t'+pvalsprint\n",
    "            header = 'S1\\tS2\\tTarget\\trank1\\t%s_p\\t%s_f1\\t%s_f2\\t%s_pnest\\t%s_p\\t%s_f1\\t%s_f2\\t%s_pnest\\t%s_p\\t%s_f1\\t%s_f2\\t%s_pnest\\tse1\\tse2\\n' % tuple(comboswanted[0:1]*4+comboswanted[1:2]*4+comboswanted[2:3]*4)\n",
    "    \n",
    "            alldata+='\\t'.join([s1,s2,target])+'\\t'+allprint+'\\t'+'\\t'.join(myinfo['se'])+'\\n'\n",
    "      \n",
    "newfile = open(pD+fh+'.'+newname+'.out'+str(myoutind)+'.tab','w')\n",
    "newfile.writelines(header+alldata)\n",
    "newfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##CASE C: (AMER, ANCASN+SIB; AMER) -- Surui/Karitiana structure\n",
    "##EXTRACT RELEVANT DATA FROM QPADM\n",
    "import projmodules as pm\n",
    "\n",
    "pD=\"/mnt/solexa/mel_yang/2.2_neolithic/qpAdm/CaseC/\"\n",
    "fh=\"UPA_all8\"\n",
    "\n",
    "sib=[\"Altaian\",\"Eskimo_Sireniki\",\"Even\",\"Itelman\",\"Mongola\",\"Tubalar\",\n",
    "     \"Ulchi\",\"Yakut\",\"Kolyma_River\"]\n",
    "\n",
    "eas=[\"Ami\",\"Atayal\",\"Dai\",\"Daur\",\"Han\",\"Hezhen\",\"Japanese\",\"Korean\",\"Kinh\",\n",
    "     \"Lahu\",\"Miao\",\"Naxi\",\"Oroqen\",\"She\",\"Tujia\",\"Yi\"]\n",
    "\n",
    "ancasn=[\"Tianyuan\",'Longlin','Longlin_com','Xinyi','Xinyi_other','Daxi',\n",
    "        'LiangDaoChineseNeolithic','Boisman_MN','BoshanChineseNeolithic',\n",
    "        'Bbdong','Linzi','HDYM1','HQSDW','Zongri','Pukagongma']\n",
    "\n",
    "eup=[\"GoyetQ116-1\",\"Vestonice16\",\"Yana_old\",\"Yana_old2\",\n",
    "     \"Malta1\",'AfontovaGora3',\"ElMiron\",\"Villabruna\",\"Satsurblia\",\"Karelia\",\n",
    "     \"Loschbour\",\"LaBrana1\",\"Hungarian.KO1\",\"Stuttgart\",\"French\"]\n",
    "namers=['Chane', 'Chipewyan', 'Cree', 'Karitiana', 'Mayan', 'Mixe', 'Nahua', 'Piapoco', \n",
    "        'Pima', 'Quechua', 'Surui', 'Zapotec', 'Clovis', 'Saqqaq']\n",
    "baseoutgroup=[\"Yoruba\",\"Ju_hoan_North\",\"Dinka\",\"Mbuti\",\"UstIshim\"]\n",
    "outs=[baseoutgroup, #0\n",
    "      baseoutgroup+[\"Kostenki14\",\"Vestonice16\",\"Tianyuan\",\"Longlin\",\"Onge\",\"Papuan\"], #1\n",
    "      baseoutgroup+[\"Kostenki14\",\"Vestonice16\"], #2\n",
    "      baseoutgroup+[\"Kostenki14\",\"Vestonice16\",\"Onge\",\"Papuan\"], #3\n",
    "      ['Kostenki14','GoyetQ116-1','UstIshim','Mota','Mbuti','Vestonice16','ElMiron','Villabruna'], #4\n",
    "      baseoutgroup+[\"Kostenki14\",\"Vestonice16\",\"Tianyuan\"]] #5\n",
    "\n",
    "s1s=namers\n",
    "s2s=ancasn+sib\n",
    "targets=namers\n",
    "newname,myoutind = ('adm_AMER_ANCASNSIB_AMER',5) \n",
    "myoutgroups=outs[myoutind]\n",
    "\n",
    "alldata = \"\"\n",
    "for ind0, s1 in enumerate(s1s):\n",
    "    if s1 in myoutgroups: continue\n",
    "    for ind2,target in enumerate(targets):\n",
    "        if s1==target: continue\n",
    "        if target in myoutgroups: continue\n",
    "        for ind1,s2 in enumerate(s2s):\n",
    "            if s2 in myoutgroups: continue\n",
    "            if len(list(set([s1,s2,target])))<3: continue\n",
    "\n",
    "            #s1,s2,target = (myind1,p2,myind2)\n",
    "            #print s1,s2,target\n",
    "            subset = 'X_%s_S1_%s_S2_%s_out%i' % (target,s1,s2,myoutind)\n",
    "            myinfo = pm.wave_extractAdmdata(pD,fh,subset,(s1,s2),target)\n",
    "            #print myinfo\n",
    "            if myinfo == 'NOFILE': continue\n",
    "            comboswanted = ['00','01','10']\n",
    "            rankswanted = ['1']\n",
    "            ranksprint = '\\t'.join([str(myinfo['f4rank'][i]) for i in rankswanted])\n",
    "            pvalsprint = '\\t'.join(['%s\\t%s\\t%s\\t%s' % tuple(myinfo['admix'][i]+myinfo['nestp'][i]) if i in myinfo['nestp'] else '%s\\t%s\\t%s\\tNA' % tuple(myinfo['admix'][i]) for i in comboswanted])\n",
    "            allprint = ranksprint+'\\t'+pvalsprint\n",
    "            header = 'S1\\tS2\\tTarget\\trank1\\t%s_p\\t%s_f1\\t%s_f2\\t%s_pnest\\t%s_p\\t%s_f1\\t%s_f2\\t%s_pnest\\t%s_p\\t%s_f1\\t%s_f2\\t%s_pnest\\tse1\\tse2\\n' % tuple(comboswanted[0:1]*4+comboswanted[1:2]*4+comboswanted[2:3]*4)\n",
    "    \n",
    "            alldata+='\\t'.join([s1,s2,target])+'\\t'+allprint+'\\t'+'\\t'.join(myinfo['se'])+'\\n'\n",
    "      \n",
    "newfile = open(pD+fh+'.'+newname+'.out'+str(myoutind)+'.tab','w')\n",
    "newfile.writelines(header+alldata)\n",
    "newfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/mel_yang/bin/qpadm_makexlsx_twosources.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ~/bin/qpadm_makexlsx_twosources.py\n",
    "#!/usr/bin/python\n",
    "\n",
    "import projmodules as pm\n",
    "import xlsxwriter as xls\n",
    "import sys\n",
    "\n",
    "#pD=\"/mnt/solexa/mel_yang/2.2_neolithic/qpAdm/CaseB/\"\n",
    "#fh,newname,myoutind = (\"UPA_all8\",'adm_SIB_ANCASN_PDEASANCASN',1) \n",
    "\n",
    "pD,fh,newname,myoutind=tuple(sys.argv[1:])\n",
    "myfile = open(pD+fh+'.'+newname+'.out'+str(myoutind)+'.tab','r')\n",
    "newfile=xls.Workbook(pD+fh+'.'+newname+'.out'+str(myoutind)+\".xlsx\")\n",
    "worksheet=newfile.add_worksheet()\n",
    "\n",
    "header = newfile.add_format({'bold': True,'align':'center','valign':'vcenter'})\n",
    "reg = newfile.add_format({'bold': False,'align':'center','valign':'vcenter'})\n",
    "regnum = newfile.add_format({'bold': False,'align':'center','valign':'vcenter','num_format': '0.000'})\n",
    "rank1 = newfile.add_format({'align':'center','valign':'vcenter','bold':False,\n",
    "                            'font_color':'#9C0006','bg_color':'#FFC7CE','num_format': '0.00'})\n",
    "pnest = newfile.add_format({'align':'center','valign':'vcenter','bold':False,\n",
    "                            'font_color':'#9C0006','bg_color':'#FFC7CE','num_format': '0.00'})\n",
    "\n",
    "keep=[\"S1\",\"S2\",\"Target\",\"rank1\",\"00_p\",\"00_f1\",\"00_f2\",\"01_p\",\"10_p\",\"01_pnest\",\"10_pnest\",\"se1\"]\n",
    "worksheet.set_column(0,3,13)\n",
    "worksheet.set_column(3,len(keep)+1,6)\n",
    "for col,i in enumerate(keep): worksheet.write_string(0,col,i,header)\n",
    "worksheet.write_string(0,12,\"pnest\",header)\n",
    "\n",
    "hiderows,satisfyrows=[],[]\n",
    "for row,line in enumerate(myfile):\n",
    "    x=line.split()\n",
    "    if row==0: headind=[x.index(i) for i in keep]; continue\n",
    "    mystats=[x[ind1] for ind1 in headind]\n",
    "    myaddon=[mypnest for mypnest in mystats[9:11] if mypnest not in [\"NA\",\"-nan\",\"nan\"]]\n",
    "    for col,i in enumerate(mystats):\n",
    "        if col in [0,1,2]: worksheet.write_string(row,col,i,reg)\n",
    "        elif col in [4,5,6,7,8,11]: \n",
    "            if i in [\"NA\",\"-nan\",\"nan\"]: worksheet.write_string(row,col,i,reg)\n",
    "            else: worksheet.write_number(row,col,float(i),regnum)\n",
    "        elif col == 3: \n",
    "            if float(i)>0.05: worksheet.write_number(row,col,float(i),rank1)\n",
    "            else: worksheet.write_number(row,col,float(i),regnum)\n",
    "        elif col in [9,10]: \n",
    "            if i in [\"NA\",\"-nan\",\"nan\"]: worksheet.write_string(row,col,i,reg); continue\n",
    "            elif float(i)<=0.05: worksheet.write_number(row,col,float(i),pnest)\n",
    "            else: worksheet.write_number(row,col,float(i),regnum)\n",
    "        else: pass\n",
    "    #print pnest\n",
    "    if len(myaddon)==0: worksheet.write_string(row,12,\"NA\",reg)\n",
    "    else: worksheet.write_number(row,12,float(myaddon[0]),regnum)\n",
    "\n",
    "myfile.close()\n",
    "newfile.close()\n",
    "\n",
    "#worksheet.autofilter(0,0,totalrows,len(keep))\n",
    "#worksheet.filter_column(keep.index('00_p'),'00_p == NA')\n",
    "#worksheet.filter_column(keep.index('rank1'),'rank1 < 0.05')\n",
    "#for row in list(set(hiderows)): worksheet.set_row(row,options={'hidden': True}) \n",
    "#print list(set(hiderows))\n",
    "#for row in satisfyrows: worksheet.set_row(row,options={'bold': True}) \n",
    "#newfile.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "            if i in [\"NA\",\"-nan\",\"nan\"]: worksheet.write_string(row,col,i,reg); continue\n",
    "            elif float(i)<=0.05: worksheet.write_number(row,col,float(i),pnest)\n",
    "            else: worksheet.write_number(row,col,float(i),regnum)\n",
    "            pnest.append(float(i))\n",
    "        else: pass\n",
    "    #print pnest\n",
    "    #if len(pnest)==0: worksheet.write_string(row,12,\"NA\",reg)\n",
    "    #else: worksheet.write_number(row,12,pnest[0],regnum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. (ANCASN, ANCASN; PDEAS+ANCASN) -- present-day mixture of past ANCASN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /mnt/solexa/mel_yang/2.2_neolithic/qpAdm/qpadm_ANC_ANC_PD+ANCEAS.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /mnt/solexa/mel_yang/2.2_neolithic/qpAdm/qpadm_ANC_ANC_PD+ANCEAS.py\n",
    "import projmodules as pm\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "import subprocess as sp\n",
    "\n",
    "indpD=\"/mnt/solexa/mel_yang/2.2_neolithic/pca/\"\n",
    "myfile=open(indpD+\"SGDP.America.txt\",'r')\n",
    "namers=[line.strip() for line in myfile]\n",
    "myfile.close()\n",
    "namers+=[\"Clovis\",\"Saqqaq\"]\n",
    "\n",
    "#myfile=open(indpD+\"SGDP.Siberia.txt\",'r')\n",
    "#sib=[line.strip() for line in myfile]\n",
    "#myfile.close()\n",
    "#sib+=[\"Kolyma_River\"]\n",
    "\n",
    "#myfile=open(indpD+\"SGDP.EastAsia.txt\",'r')\n",
    "#eas=[line.strip() for line in myfile]\n",
    "#myfile.close()\n",
    "\n",
    "sib=[\"Altaian\",\"Eskimo_Sireniki\",\"Even\",\"Itelman\",\"Mongola\",\"Tubalar\",\n",
    "     \"Ulchi\",\"Yakut\",\"Kolyma_River\"]\n",
    "\n",
    "eas=[\"Ami\",\"Atayal\",\"Dai\",\"Daur\",\"Han\",\"Hezhen\",\"Japanese\",\"Korean\",\"Kinh\",\n",
    "     \"Lahu\",\"Miao\",\"Naxi\",\"Oroqen\",\"She\",\"Tujia\",\"Yi\"]\n",
    "\n",
    "ancasn=[\"Tianyuan\",'Longlin','Longlin_com','Xinyi','Xinyi_other','Daxi',\n",
    "        'LiangDaoChineseNeolithic','Boisman_MN','BoshanChineseNeolithic',\n",
    "        'Bbdong','Linzi','HDYM1','HQSDW','Zongri','Pukagongma']\n",
    "\n",
    "eup=[\"GoyetQ116-1\",\"Vestonice16\",\"Yana_old\",\"Yana_old2\",\n",
    "     \"Malta1\",'AfontovaGora3',\"ElMiron\",\"Villabruna\",\"Satsurblia\",\"Karelia\",\n",
    "     \"Loschbour\",\"LaBrana1\",\"Hungarian.KO1\",\"Stuttgart\",\"French\"]\n",
    "\n",
    "\n",
    "##left=[[target, s1, s2]]\n",
    "left=[[k, i, j] for i in ancasn for j in ancasn for k in eas if i!=j and i!=k and j!=k] \n",
    "#left=[[k, i, j] for i in ancasn for j in ancasn for k in ancasn if i!=j and i!=k and j!=k] \n",
    "print len(left)\n",
    "\n",
    "def dowork(mytup):\n",
    "    myleft,myleftid=mytup\n",
    "    outpD=\"/mnt/solexa/mel_yang/2.2_neolithic/qpAdm/CaseA/\"\n",
    "    pD=\"/mnt/solexa/mel_yang/data/2.2M/\"\n",
    "    fh=\"UPA_all8\"\n",
    "    baseoutgroup=[\"Yoruba\",\"Ju_hoan_North\",\"Dinka\",\"Mbuti\",\"UstIshim\"]\n",
    "    outs=[baseoutgroup, #0\n",
    "          baseoutgroup+[\"Kostenki14\",\"Vestonice16\",\"Tianyuan\",\"Longlin\",\"Onge\",\"Papuan\"], #1\n",
    "          baseoutgroup+[\"Kostenki14\",\"Vestonice16\"], #2\n",
    "          baseoutgroup+[\"Kostenki14\",\"Vestonice16\",\"Onge\",\"Papuan\"], \n",
    "          baseoutgroup+[\"Kostenki14\",\"Vestonice16\",\"Tianyuan\",\"Onge\",\"Papuan\"]] #4\n",
    "          \n",
    "    for outid,out in enumerate(outs):\n",
    "        if outid in [0,1,2,3]: continue #[5,7,12,13]: continue\n",
    "        if myleft[0] in out or myleft[1] in out or myleft[2] in out: continue\n",
    "        bck = 'X_%s_S1_%s_S2_%s_out%i' % tuple(myleft+[outid])\n",
    "        pm.wave_run(myleft, out, pD, fh, bck, outpd=outpD)\n",
    "        pm.wave_adm_run(myleft, out, pD, fh, bck, outpd=outpD)\n",
    "        \n",
    "myinputs=[(myleft,ind,) for ind,myleft in enumerate(left)] \n",
    "print len(myinputs)\n",
    "mypool = Pool(20)\n",
    "results = mypool.map(dowork, myinputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. (SIB, ANCASN; PDEAS) --PDEAS have more NAsn ancestry than ancient SASN??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /mnt/solexa/mel_yang/2.2_neolithic/qpAdm/CaseB_SIB_ANCPDEAS_ANCPDEAS.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /mnt/solexa/mel_yang/2.2_neolithic/qpAdm/CaseB_SIB_ANCPDEAS_ANCPDEAS.py\n",
    "import projmodules as pm\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "import subprocess as sp\n",
    "\n",
    "sib=[\"Altaian\",\"Eskimo_Sireniki\",\"Even\",\"Itelman\",\"Mongola\",\"Tubalar\",\n",
    "     \"Ulchi\",\"Yakut\",\"Kolyma_River\"]\n",
    "\n",
    "eas=[\"Ami\",\"Atayal\",\"Dai\",\"Daur\",\"Han\",\"Hezhen\",\"Japanese\",\"Korean\",\"Kinh\",\n",
    "     \"Lahu\",\"Miao\",\"Naxi\",\"Oroqen\",\"She\",\"Tujia\",\"Yi\"]\n",
    "\n",
    "ancasn=[\"Tianyuan\",'Longlin','Longlin_com','Xinyi','Xinyi_other','Daxi',\n",
    "        'LiangDaoChineseNeolithic','Boisman_MN','BoshanChineseNeolithic',\n",
    "        'Bbdong','Linzi','HDYM1','HQSDW','Zongri','Pukagongma']\n",
    "\n",
    "eup=[\"GoyetQ116-1\",\"Vestonice16\",\"Yana_old\",\"Yana_old2\",\n",
    "     \"Malta1\",'AfontovaGora3',\"ElMiron\",\"Villabruna\",\"Satsurblia\",\"Karelia\",\n",
    "     \"Loschbour\",\"LaBrana1\",\"Hungarian.KO1\",\"Stuttgart\",\"French\"]\n",
    "\n",
    "\n",
    "##left=[[target, s1, s2]]\n",
    "left=[[k, i, j] for i in sib for j in ancasn+eas for k in ancasn+eas if i!=j and i!=k and j!=k] \n",
    "print len(left)\n",
    "\n",
    "def dowork(mytup):\n",
    "    myleft,myleftid=mytup\n",
    "    outpD=\"/mnt/solexa/mel_yang/2.2_neolithic/qpAdm/CaseB/\"\n",
    "    pD=\"/mnt/solexa/mel_yang/data/2.2M/\"\n",
    "    fh=\"UPA_all8\"\n",
    "    baseoutgroup=[\"Yoruba\",\"Ju_hoan_North\",\"Dinka\",\"Mbuti\",\"UstIshim\"]\n",
    "    outs=[baseoutgroup, #0\n",
    "          baseoutgroup+[\"Kostenki14\",\"Vestonice16\",\"Tianyuan\",\"Longlin\",\"Onge\",\"Papuan\"], #1\n",
    "          baseoutgroup+[\"Kostenki14\",\"Vestonice16\"], #2\n",
    "          baseoutgroup+[\"Kostenki14\",\"Vestonice16\",\"Onge\",\"Papuan\"], \n",
    "          baseoutgroup+[\"Kostenki14\",\"Vestonice16\",\"Tianyuan\",\"Onge\",\"Papuan\"]] #4\n",
    "          \n",
    "    for outid,out in enumerate(outs):\n",
    "        if outid in [0,2,3]: continue \n",
    "        if myleft[2] in ancasn and myleft[0] in eas and outid==1: continue ##THOSE ALREADY DONE!\n",
    "        if myleft[0] in out or myleft[1] in out or myleft[2] in out: continue\n",
    "        bck = 'X_%s_S1_%s_S2_%s_out%i' % tuple(myleft+[outid])\n",
    "        pm.wave_run(myleft, out, pD, fh, bck, outpd=outpD)\n",
    "        pm.wave_adm_run(myleft, out, pD, fh, bck, outpd=outpD)\n",
    "        \n",
    "myinputs=[(myleft,ind,) for ind,myleft in enumerate(left)] \n",
    "print len(myinputs)\n",
    "mypool = Pool(20)\n",
    "results = mypool.map(dowork, myinputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. (AMER, ANCASN+SIB; AMER) -- Surui/Karitiana affinities?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /mnt/solexa/mel_yang/2.2_neolithic/qpAdm/CaseC_AMER_ANCSIB_AMER.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /mnt/solexa/mel_yang/2.2_neolithic/qpAdm/CaseC_AMER_ANCSIB_AMER.py\n",
    "import projmodules as pm\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "import subprocess as sp\n",
    "\n",
    "indpD=\"/mnt/solexa/mel_yang/2.2_neolithic/pca/\"\n",
    "myfile=open(indpD+\"SGDP.America.txt\",'r')\n",
    "namers=[line.strip() for line in myfile]\n",
    "myfile.close()\n",
    "namers+=[\"Clovis\",\"Saqqaq\"]\n",
    "namers.remove(\"Mixtec\")\n",
    "\n",
    "#myfile=open(indpD+\"SGDP.Siberia.txt\",'r')\n",
    "#sib=[line.strip() for line in myfile]\n",
    "#myfile.close()\n",
    "#sib+=[\"Kolyma_River\"]\n",
    "\n",
    "#myfile=open(indpD+\"SGDP.EastAsia.txt\",'r')\n",
    "#eas=[line.strip() for line in myfile]\n",
    "#myfile.close()\n",
    "\n",
    "sib=[\"Altaian\",\"Eskimo_Sireniki\",\"Even\",\"Itelman\",\"Mongola\",\"Tubalar\",\n",
    "     \"Ulchi\",\"Yakut\",\"Kolyma_River\"]\n",
    "\n",
    "eas=[\"Ami\",\"Atayal\",\"Dai\",\"Daur\",\"Han\",\"Hezhen\",\"Japanese\",\"Korean\",\"Kinh\",\n",
    "     \"Lahu\",\"Miao\",\"Naxi\",\"Oroqen\",\"She\",\"Tujia\",\"Yi\"]\n",
    "\n",
    "ancasn=[\"Tianyuan\",'Longlin','Longlin_com','Xinyi','Xinyi_other','Daxi',\n",
    "        'LiangDaoChineseNeolithic','Boisman_MN','BoshanChineseNeolithic',\n",
    "        'Bbdong','Linzi','HDYM1','HQSDW','Zongri','Pukagongma']\n",
    "\n",
    "eup=[\"GoyetQ116-1\",\"Vestonice16\",\"Yana_old\",\"Yana_old2\",\n",
    "     \"Malta1\",'AfontovaGora3',\"ElMiron\",\"Villabruna\",\"Satsurblia\",\"Karelia\",\n",
    "     \"Loschbour\",\"LaBrana1\",\"Hungarian.KO1\",\"Stuttgart\",\"French\"]\n",
    "\n",
    "\n",
    "##left=[[target, s1, s2]]\n",
    "left=[[k, i, j] for i in namers for j in ancasn+sib for k in namers if i!=j and i!=k and j!=k] \n",
    "print len(left)\n",
    "\n",
    "def dowork(mytup):\n",
    "    myleft,myleftid=mytup\n",
    "    outpD=\"/mnt/solexa/mel_yang/2.2_neolithic/qpAdm/CaseC/\"\n",
    "    pD=\"/mnt/solexa/mel_yang/data/2.2M/\"\n",
    "    fh=\"UPA_all8\"\n",
    "    baseoutgroup=[\"Yoruba\",\"Ju_hoan_North\",\"Dinka\",\"Mbuti\",\"UstIshim\"]\n",
    "    outs=[baseoutgroup, #0\n",
    "          baseoutgroup+[\"Kostenki14\",\"Vestonice16\",\"Tianyuan\",\"Longlin\",\"Onge\",\"Papuan\"], #1\n",
    "          baseoutgroup+[\"Kostenki14\",\"Vestonice16\"], #2\n",
    "          baseoutgroup+[\"Kostenki14\",\"Vestonice16\",\"Onge\",\"Papuan\"], #3\n",
    "          ['Kostenki14','GoyetQ116-1','UstIshim','Mota','Mbuti','Vestonice16','ElMiron','Villabruna'], #4\n",
    "          baseoutgroup+[\"Kostenki14\",\"Vestonice16\",\"Tianyuan\"]] #5\n",
    "     \n",
    "    for outid,out in enumerate(outs):\n",
    "        if outid not in [5]: continue #[5,7,12,13]: continue\n",
    "        if myleft[0] in out or myleft[1] in out or myleft[2] in out: continue\n",
    "        bck = 'X_%s_S1_%s_S2_%s_out%i' % tuple(myleft+[outid])\n",
    "        pm.wave_run(myleft, out, pD, fh, bck, outpd=outpD)\n",
    "        pm.wave_adm_run(myleft, out, pD, fh, bck, outpd=outpD)\n",
    "        \n",
    "myinputs=[(myleft,ind,) for ind,myleft in enumerate(left)] \n",
    "print len(myinputs)\n",
    "mypool = Pool(20)\n",
    "results = mypool.map(dowork, myinputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. (EUR+Natufian, ANCASN; PDEAS+ANCASN) -- BE/ANE/WHG influences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /mnt/solexa/mel_yang/2.2_neolithic/qpAdm/CaseD_AMER_ANCSIB_AMER.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /mnt/solexa/mel_yang/2.2_neolithic/qpAdm/CaseD_AMER_ANCSIB_AMER.py\n",
    "import projmodules as pm\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "import subprocess as sp\n",
    "\n",
    "indpD=\"/mnt/solexa/mel_yang/2.2_neolithic/pca/\"\n",
    "myfile=open(indpD+\"SGDP.America.txt\",'r')\n",
    "namers=[line.strip() for line in myfile]\n",
    "myfile.close()\n",
    "namers+=[\"Clovis\",\"Saqqaq\"]\n",
    "namers.remove(\"Mixtec\")\n",
    "\n",
    "#myfile=open(indpD+\"SGDP.Siberia.txt\",'r')\n",
    "#sib=[line.strip() for line in myfile]\n",
    "#myfile.close()\n",
    "#sib+=[\"Kolyma_River\"]\n",
    "\n",
    "#myfile=open(indpD+\"SGDP.EastAsia.txt\",'r')\n",
    "#eas=[line.strip() for line in myfile]\n",
    "#myfile.close()\n",
    "\n",
    "sib=[\"Altaian\",\"Eskimo_Sireniki\",\"Even\",\"Itelman\",\"Mongola\",\"Tubalar\",\n",
    "     \"Ulchi\",\"Yakut\",\"Kolyma_River\"]\n",
    "\n",
    "eas=[\"Ami\",\"Atayal\",\"Dai\",\"Daur\",\"Han\",\"Hezhen\",\"Japanese\",\"Korean\",\"Kinh\",\n",
    "     \"Lahu\",\"Miao\",\"Naxi\",\"Oroqen\",\"She\",\"Tujia\",\"Yi\"]\n",
    "\n",
    "ancasn=[\"Tianyuan\",'Longlin','Longlin_com','Xinyi','Xinyi_other','Daxi',\n",
    "        'LiangDaoChineseNeolithic','Boisman_MN','BoshanChineseNeolithic',\n",
    "        'Bbdong','Linzi','HDYM1','HQSDW','Zongri','Pukagongma']\n",
    "\n",
    "eup=[\"GoyetQ116-1\",\"Vestonice16\",\"Yana_old\",\"Yana_old2\",\n",
    "     \"Malta1\",'AfontovaGora3',\"ElMiron\",\"Villabruna\",\"Satsurblia\",\"Karelia\",\n",
    "     \"Loschbour\",\"LaBrana1\",\"Hungarian.KO1\",\"Stuttgart\",\"French\"]\n",
    "\n",
    "\n",
    "##left=[[target, s1, s2]]\n",
    "left=[[k, i, j] for i in eup for j in ancasn for k in eas+ancasn if i!=j and i!=k and j!=k] \n",
    "print len(left)\n",
    "\n",
    "def dowork(mytup):\n",
    "    myleft,myleftid=mytup\n",
    "    outpD=\"/mnt/solexa/mel_yang/2.2_neolithic/qpAdm/CaseD/\"\n",
    "    pD=\"/mnt/solexa/mel_yang/data/2.2M/\"\n",
    "    fh=\"UPA_all8\"\n",
    "    baseoutgroup=[\"Yoruba\",\"Ju_hoan_North\",\"Dinka\",\"Mbuti\",\"UstIshim\"]\n",
    "    outs=[baseoutgroup, #0\n",
    "          baseoutgroup+[\"Kostenki14\",\"Vestonice16\",\"Tianyuan\",\"Longlin\",\"Onge\",\"Papuan\"], #1\n",
    "          baseoutgroup+[\"Kostenki14\",\"Vestonice16\"], #2\n",
    "          baseoutgroup+[\"Kostenki14\",\"Vestonice16\",\"Onge\",\"Papuan\"], #3\n",
    "          baseoutgroup+[\"Onge\",\"Papuan\"]] #4\n",
    "     \n",
    "    for outid,out in enumerate(outs):\n",
    "        #if outid not in [0]: continue #[5,7,12,13]: continue\n",
    "        if myleft[0] in out or myleft[1] in out or myleft[2] in out: continue\n",
    "        bck = 'X_%s_S1_%s_S2_%s_out%i' % tuple(myleft+[outid])\n",
    "        pm.wave_run(myleft, out, pD, fh, bck, outpd=outpD)\n",
    "        pm.wave_adm_run(myleft, out, pD, fh, bck, outpd=outpD)\n",
    "        \n",
    "myinputs=[(myleft,ind,) for ind,myleft in enumerate(left)] \n",
    "print len(myinputs)\n",
    "mypool = Pool(20)\n",
    "results = mypool.map(dowork, myinputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /mnt/solexa/mel_yang/2.2_neolithic/qpAdm/CaseE_NEAS_aNEAS_EAS_SDEAS.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /mnt/solexa/mel_yang/2.2_neolithic/qpAdm/CaseE_NEAS_aNEAS_EAS_SDEAS.py\n",
    "import projmodules as pm\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "import subprocess as sp\n",
    "\n",
    "sib=[\"Altaian\",\"Eskimo_Sireniki\",\"Even\",\"Itelman\",\"Mongola\",\"Tubalar\",\n",
    "     \"Ulchi\",\"Yakut\",\"Kolyma_River\"]\n",
    "\n",
    "eas=[\"Ami\",\"Atayal\",\"Dai\",\"Daur\",\"Han\",\"Hezhen\",\"Japanese\",\"Korean\",\"Kinh\",\n",
    "     \"Lahu\",\"Miao\",\"Naxi\",\"Oroqen\",\"She\",\"Tujia\",\"Yi\"]\n",
    "\n",
    "ancasn=[\"Tianyuan\",'Longlin','Longlin_com','Xinyi','Xinyi_other','Daxi',\n",
    "        'LiangDaoChineseNeolithic','Boisman_MN','BoshanChineseNeolithic',\n",
    "        'Bbdong','Linzi','HDYM1','HQSDW','Zongri','Pukagongma']\n",
    "\n",
    "eup=[\"GoyetQ116-1\",\"Vestonice16\",\"Yana_old\",\"Yana_old2\",\n",
    "     \"Malta1\",'AfontovaGora3',\"ElMiron\",\"Villabruna\",\"Satsurblia\",\"Karelia\",\n",
    "     \"Loschbour\",\"LaBrana1\",\"Hungarian.KO1\",\"Stuttgart\",\"French\"]\n",
    "targets=[\"Korean\",\"Japanese\",\"Daur\",\"Han\",\"Hezhen\",\"Oroqen\"]\n",
    "s1s=['Boisman_MN','BoshanChineseNeolithic','HDYM1','HQSDW','Bbdong','Linzi']\n",
    "s2s=[\"Ami\",\"Atayal\",\"Dai\",\"Han\",\"She\",\"Tujia\",'Xinyi','Longlin','LiangDaoChineseNeolithic']\n",
    "s3s=['BoshanChineseNeolithic','Bbdong','Linzi']\n",
    "left=[[]]\n",
    "##left=[[target, s1, s2]]\n",
    "left=[[k, i, j, l] for i in s1s for j in s2s for k in targets for l in s3s if len(list(set([i,j,k,l])))==4] \n",
    "print len(left)\n",
    "\n",
    "def dowork(mytup):\n",
    "    myleft,myleftid=mytup\n",
    "    outpD=\"/mnt/solexa/mel_yang/2.2_neolithic/qpAdm/CaseE/\"\n",
    "    pD=\"/mnt/solexa/mel_yang/data/2.2M/\"\n",
    "    fh=\"UPA_all8\"\n",
    "    baseoutgroup=[\"Yoruba\",\"Ju_hoan_North\",\"Dinka\",\"Mbuti\",\"UstIshim\"]\n",
    "    outs=[baseoutgroup, #0\n",
    "          baseoutgroup+[\"Kostenki14\",\"Vestonice16\",\"Tianyuan\",\"Longlin\",\"Onge\",\"Papuan\"], #1\n",
    "          baseoutgroup+[\"Kostenki14\",\"Vestonice16\"], #2\n",
    "          baseoutgroup+[\"Kostenki14\",\"Vestonice16\",\"Onge\",\"Papuan\"], \n",
    "          baseoutgroup+[\"Kostenki14\",\"Vestonice16\",\"Tianyuan\",\"Onge\",\"Papuan\"]] #4\n",
    "          \n",
    "    for outid,out in enumerate(outs):\n",
    "        if outid in [0,2,3]: continue \n",
    "        #if myleft[2] in ancasn and myleft[0] in eas and outid==1: continue ##THOSE ALREADY DONE!\n",
    "        if myleft[0] in out or myleft[1] in out or myleft[2] in out or myleft[3] in out: continue\n",
    "        bck = 'X_%s_S1_%s_S2_%s_S3_%s_out%i' % tuple(myleft+[outid])\n",
    "        pm.wave_run(myleft, out, pD, fh, bck, outpd=outpD)\n",
    "        pm.wave_adm_run(myleft, out, pD, fh, bck, outpd=outpD)\n",
    "        \n",
    "myinputs=[(myleft,ind,) for ind,myleft in enumerate(left)] \n",
    "print len(myinputs)\n",
    "mypool = Pool(20)\n",
    "results = mypool.map(dowork, myinputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
