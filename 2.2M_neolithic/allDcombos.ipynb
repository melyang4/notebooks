{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting D combos\n",
    "\n",
    "In each set of D(X,Y;Z,O), D(X,Z;Y,O) and D(Z,Y,X,O), or D1, D2, D3, there are three possible answers: >, < or =. How many unique combinations are there? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'slightconnect_1OO2': ['>==', '<==', '=>=', '=<=', '==>', '==<'], 'treeadmix_21': ['>>>', '>><', '><>', '<><', '<<>', '<<<'], 'allconnect_111': ['><<', '<>>'], 'similaradmix_11OO1': ['>>=', '><=', '>=<', '<>=', '<=>', '<=<', '=>>', '=<>', '=<<'], 'norelation_OO3': ['==='], 'treenoadmix_2OO1': ['>=>', '<<=', '=><']}\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "myoptions=[\">\",\"<\",\"=\"]\n",
    "mytrees=[\"XYZ\",\"XZY\",\"ZYX\"]\n",
    "mypats={\"XYZ\":[\"XZ\",\"YZ\",\"OO\"],\"XZY\":[\"XY\",\"YZ\",\"OO\"],\"ZYX\":[\"XZ\",\"XY\",\"OO\"]}\n",
    "mysets=[]\n",
    "for i in myoptions:\n",
    "    for j in myoptions:\n",
    "        for k in myoptions:\n",
    "            mysets.append([i,j,k])\n",
    "            \n",
    "treenoadmix=(2,'OO')\n",
    "treeadmix=(2,1)\n",
    "similarrel=(1,1,'OO')\n",
    "genpat=[\"21\",\"1OO2\",\"11OO1\",\"111\",\"OO3\",\"2OO1\"]\n",
    "genpatnames=[\"treeadmix\",\"slightconnect\",\"similaradmix\",\"allconnect\",\"norelation\",\"treenoadmix\"]\n",
    "uniqsets=collections.defaultdict(list)\n",
    "for ind, i in enumerate(mysets):\n",
    "    sisters = [ mypats[mytrees[treeind]][myoptions.index(equality)] for treeind,equality in enumerate(i) ]\n",
    "    counts=collections.Counter(sisters)\n",
    "    mystats=counts.most_common()\n",
    "    treepat=''.join([ str(mystat[1]) for mystat in mystats if mystat[0] != 'OO' ])\n",
    "    oos=[ mystat[0]+str(mystat[1]) for mystat in mystats if mystat[0] == 'OO' ]\n",
    "    oos1=oos[0] if len(oos)>0 else ''\n",
    "    uniqsets[treepat+oos1].append(''.join(i))\n",
    "    #print ind,''.join(i), counts, treepat+oos1\n",
    "    \n",
    "dictpat={}\n",
    "for i in uniqsets: \n",
    "    dictpat[genpatnames[genpat.index(i)]+\"_\"+i] = uniqsets[i]\n",
    "print dictpat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "pd=\"/mnt/solexa/mel_yang/2.2_neolithic/Dstats/frommpi/\"\n",
    "fh=\"UPA_all8\"\n",
    "tv=\"all\"\n",
    "pop1=\"EUPASNAMER\"\n",
    "indiv=\"Linzi\"\n",
    "out=\"Mbuti\"\n",
    "subset1=\"%s_%s_%s_%s\" % (pop1,pop1,indiv,out)\n",
    "subset2=\"%s_%s_%s_%s\" % (indiv,pop1,pop1,out)\n",
    "DorZind=7 ##Zind (5 is Dind)\n",
    "\n",
    "myfile1=open(pd+\"%s.D.%s.%s.log\" % (fh,tv,subset1) )\n",
    "myfile2=open(pd+\"%s.D.%s.%s.log\" % (fh,tv,subset2) )\n",
    "results=[line.split() for line in myfile1 if line.split()[0]==\"result:\"]\n",
    "results+=[line.split() for line in myfile2 if line.split()[0]==\"result:\"]\n",
    "myfile1.close()\n",
    "myfile2.close()\n",
    "\n",
    "opptype={\">\":\"<\",\"<\":\">\",\"=\":\"=\"}\n",
    "\n",
    "pops={}\n",
    "uniqueset=[]\n",
    "for mylst in results:\n",
    "    mypopns=mylst[1:4]\n",
    "    val=float(mylst[DorZind])\n",
    "    if val>=2.5:mytype=\">\"\n",
    "    elif val<=-2.5: mytype=\"<\"\n",
    "    else: mytype=\"=\"\n",
    "    checkind=[ind for ind,i in enumerate(uniqueset) if set(i)==set(mypopns)]\n",
    "    if len(checkind)==0: \n",
    "        uniqueset.append(tuple(mypopns))\n",
    "        x,y,z=tuple(mypopns)\n",
    "    else: x,y,z=uniqueset[checkind[0]]\n",
    "\n",
    "    if (x,y,z) not in pops: pops[(x,y,z)]=[0,0,0,0,0,0]\n",
    "    \n",
    "    if x==mypopns[0] and y==mypopns[1] and z==mypopns[2]: pops[(x,y,z)][0]=mytype\n",
    "    elif x==mypopns[0] and y==mypopns[2] and z==mypopns[1]: pops[(x,y,z)][1]=mytype\n",
    "    elif x==mypopns[2] and y==mypopns[1] and z==mypopns[0]: pops[(x,y,z)][2]=mytype\n",
    "    elif x==mypopns[1] and y==mypopns[0] and z==mypopns[2]: pops[(x,y,z)][0]=opptype[mytype]\n",
    "    elif x==mypopns[1] and y==mypopns[2] and z==mypopns[0]: pops[(x,y,z)][1]=opptype[mytype]\n",
    "    elif x==mypopns[2] and y==mypopns[0] and z==mypopns[1]: pops[(x,y,z)][2]=opptype[mytype]\n",
    "    else: print x,y,z; continue\n",
    "\n",
    "        \n",
    "        \n",
    "genpat={'slightconnect_1OO2': ['>==', '<==', '=>=', '=<=', '==>', '==<'], \n",
    "       'treeadmix_21': ['>>>', '>><', '><>', '<><', '<<>', '<<<'], \n",
    "       'allconnect_111': ['><<', '<>>'], \n",
    "       'similaradmix_11OO1': ['>>=', '><=', '>=<', '<>=', '<=>', '<=<', '=>>', '=<>', '=<<'], \n",
    "       'norelation_OO3': ['==='], \n",
    "       'treenoadmix_2OO1': ['>=>', '<<=', '=><']}\n",
    "\n",
    "mypatname=[]\n",
    "mypats=[]\n",
    "for i in genpat: \n",
    "    mypatname+=[i]*len(genpat[i])\n",
    "    mypats+=genpat[i]\n",
    "relationships=[\"X_02\",\"X_12\",\"X_01\",\"X_12\",\"X_02\",\"X_01\",\"02_01\",\"01_02\",\"02_12\",\"01_12\",\"12_02\",\"12_01\",\n",
    "               \"X_X_A\",\"X_X_A\",\"X_0\",\"X_0\",\"X_1\",\"X_0\",\"X_1\",\"X_1\",\"X_2\",\"X_2\",\"X_2\",\"X_X_X\",\"02_X\",\"12_X\",\"01_X\"]\n",
    "\n",
    "newsubset=\"Linzi_EUPASNAMER\"\n",
    "newfile=open(pd+\"%s.D.%s.patterns.%s.txt\" % (fh,tv,newsubset) ,'w')\n",
    "newfile.write(\"X\\tY\\tZ\\ttitle\\tpattern\\ttree\\tadmix\\n\")\n",
    "for ind,mypop in enumerate(pops): \n",
    "    mypattern = ''.join(pops[mypop][:3])\n",
    "    mytitle=mypatname[mypats.index(mypattern)]\n",
    "    myrel=relationships[mypats.index(mypattern)].split('_')\n",
    "    if myrel[0]!=\"X\": \n",
    "        other=[i for i in '012' if i not in myrel[0]][0]\n",
    "        #print other\n",
    "        tree=\"(%s,%s),%s\" % (tuple([mypop[int(i)] for i in myrel[0]]+[mypop[int(other)]]))\n",
    "    else: tree=\"NA\"\n",
    "        \n",
    "    if myrel[1]!=\"X\":\n",
    "        if len(myrel[1]) == 2: admix=\"%s<->%s\" % (tuple([mypop[int(i)] for i in myrel[1]]))\n",
    "        else: \n",
    "            both=int(myrel[1][0])\n",
    "            others=[i for i in [0,1,2] if i != both]\n",
    "            admix=\"%s<->%s,%s<->%s\" % (mypop[both],mypop[others[0]],mypop[both],mypop[others[1]])\n",
    "    else: \n",
    "        if len(myrel)==2: admix=\"NA\"\n",
    "        else:\n",
    "            if myrel[2]==\"A\": admix=\"ALL\"\n",
    "            elif myrel[2]==\"X\": admix=\"NONE\"\n",
    "    newfile.write('\\t'.join(mypop)+'\\t'+mytitle+'\\t'+mypattern+'\\t'+tree+'\\t'+admix+'\\n')\n",
    "\n",
    "    #if ind==10: break\n",
    "newfile.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "genpat={'slightconnect_1OO2': ['>==', '<==', '=>=', '=<=', '==>', '==<'], \n",
    "       'treeadmix_21': ['>>>', '>><', '><>', '<><', '<<>', '<<<'], \n",
    "       'allconnect_111': ['><<', '<>>'], \n",
    "       'similaradmix_11OO1': ['>>=', '><=', '>=<', '<>=', '<=>', '<=<', '=>>', '=<>', '=<<'], \n",
    "       'norelation_OO3': ['==='], \n",
    "       'treenoadmix_2OO1': ['>=>', '<<=', '=><']}\n",
    "\n",
    "mypatname=[]\n",
    "mypats=[]\n",
    "for i in genpat: \n",
    "    mypatname+=[i]*len(genpat[i])\n",
    "    mypats+=genpat[i]\n",
    "relationships=[\"X_02\",\"X_12\",\"X_01\",\"X_12\",\"X_02\",\"X_01\",\"02_01\",\"01_02\",\"02_12\",\"01_12\",\"12_02\",\"12_01\",\n",
    "               \"X_X_A\",\"X_X_A\",\"X_0\",\"X_0\",\"X_1\",\"X_0\",\"X_1\",\"X_1\",\"X_2\",\"X_2\",\"X_2\",\"X_X_X\",\"02_X\",\"12_X\",\"01_X\"]\n",
    "\n",
    "\n",
    "eas=[\"Oroqen\",\"Daur\",\"Hezhen\",\"Xibo\",\"Japanese\",\"Korean\",\n",
    "        \"Tu\",\"Han\",\"Tujia\",\"Miao\",\"Yi\",\"She\",\"Naxi\",\"Atayal\",\n",
    "        \"Ami\",\"Lahu\",\"Dai\",\"Kinh\",\"Burmese\",\"Thai\",\"Cambodian\",\"Tibetan\",\"Uygur\"]\n",
    "amer=[\"Clovis\",\"Pima\",\"Mayan\",\"Mixe\",\"Zapotec\",\"Piapoco\",\n",
    "        \"Karitiana\",\"Surui\",\"Quechua\",\"Chane\",\"Nahua\",\n",
    "        \"Cree\",\"Chipewyan\",'Saqqaq']\n",
    "sib=[\"Aleut\",\"Tlingit\",\"Mansi\",\"Chukchi\",\"Tubalar\",\"Kyrgyz\",\"Ulchi\",\n",
    "    \"Mongola\",\"Altaian\",\"Even\",\"Yakut\",\"Itelman\",\n",
    "    \"Eskimo_Sireniki\",\"Eskimo_Naukan\",\"Eskimo_Chaplin\"]\n",
    "pac=[\"Onge\",\"Papuan\",\"Maori\",\"Igorot\",\"Hawaiian\",\n",
    "         \"Dusun\",\"Bougainville\",\"Australian\"]\n",
    "oas=[\"Sherpa\",\"Kusunda\"]\n",
    "anc=[\"Tianyuan\",'Longlin','Longlin_com','Xinyi',\n",
    "        'Xinyi_other','Daxi','LiangDaoChineseNeolithic','Boisman_MN',\n",
    "        'BoshanChineseNeolithic','Bbdong','Linzi','HDYM1','HQSDW',\n",
    "        'Zongri','Pukagongma','Chokhopani1','Mebrak','Samdzong',\n",
    "        'Kolyma_River',\"Donghuigou\",\"Balikun\"]\n",
    "eur=[\"UstIshim\",\"Oase1\",\"Kostenki14\",\"GoyetQ116-1\",\n",
    "     \"Vestonice16\",\"Yana_old\",\"Yana_old2\",\n",
    "     \"Malta1\",'AfontovaGora3',\"ElMiron\",\"Villabruna\",\"Bichon\",\n",
    "     \"Satsurblia\",\"Kotias\",\"Karelia\",\"Motala12\",\"Loschbour\",\"LaBrana1\",\n",
    "     \"Hungarian.KO1\",\"Stuttgart\",\"French\",\"Sardinian\",\"Saami\"]\n",
    "asn=eas+amer+sib+pac+oas+anc\n",
    "popties=[\"(ASN,ASN),EUR\",\"(EUR,EUR),ASN\",\"(EAS,EAS),ASN-EAS\",\"(AMER,AMER),ASN-AMER\",\n",
    "         \"(EAS,EAS),ASN-EAS\",\"(SIB,SIB),ASN-SIB\",\"(OAS,OAS),ASN-OAS\",\"(PAC,PAC),ASN-PAC\"]\n",
    "popchecks=[(asn,eur),(eur,asn),(eas,list(set(asn).difference(eas))),(amer,list(set(asn).difference(amer))),\n",
    "           (eas,list(set(asn).difference(eas))),(sib,list(set(asn).difference(sib))),(oas,list(set(asn).difference(oas))),(pac,list(set(asn).difference(pac)))]\n",
    "\n",
    "\n",
    "newsubset=\"Linzi_EUPASNAMER\"\n",
    "newfile=open(pd+\"%s.D.%s.patterns.%s.txt\" % (fh,tv,newsubset) ,'w')\n",
    "newfile.write(\"X\\tY\\tZ\\ttitle\\tpattern\\ttree\\tadmix\\trelationship\\n\")\n",
    "for ind,mypop in enumerate(pops): \n",
    "    mypattern = ''.join(pops[mypop][:3])\n",
    "    mytitle=mypatname[mypats.index(mypattern)]\n",
    "    myrel=relationships[mypats.index(mypattern)].split('_')\n",
    "    \n",
    "    treeind=(-1,-1,-1)\n",
    "    if myrel[0]!=\"X\": \n",
    "        other=[i for i in '012' if i not in myrel[0]][0]\n",
    "        #print other\n",
    "        tree=\"(%s,%s),%s\" % (tuple([mypop[int(i)] for i in myrel[0]]+[mypop[int(other)]]))\n",
    "        treeind=tuple([int(i) for i in myrel[0]]+[int(other)])\n",
    "    else: tree=\"NA\"\n",
    "        \n",
    "    if myrel[1]!=\"X\":\n",
    "        if len(myrel[1]) == 2: admix=\"%s<->%s\" % (tuple([mypop[int(i)] for i in myrel[1]]))\n",
    "        else: \n",
    "            both=int(myrel[1][0])\n",
    "            others=[i for i in [0,1,2] if i != both]\n",
    "            admix=\"%s<->%s,%s<->%s\" % (mypop[both],mypop[others[0]],mypop[both],mypop[others[1]])\n",
    "    else: \n",
    "        if len(myrel)==2: admix=\"NA\"\n",
    "        else:\n",
    "            if myrel[2]==\"A\": admix=\"ALL\"\n",
    "            elif myrel[2]==\"X\": admix=\"NONE\"\n",
    "                \n",
    "    if treeind[0]!=-1:\n",
    "        mypoprels = [ ind for ind,i in enumerate(popties) if mypop[treeind[0]] in popchecks[ind][0] and mypop[treeind[1]] in popchecks[ind][0] and mypop[treeind[2]] in popchecks[ind][1]] \n",
    "        if len(mypoprels)==0: mycategory=\"NA\"\n",
    "        else: mycategory=popties[mypoprels[0]]\n",
    "    else: mycategory=\"NA\"\n",
    "        \n",
    "    newfile.write('\\t'.join(mypop)+'\\t'+mytitle+'\\t'+mypattern+'\\t'+tree+'\\t'+admix+'\\t'+mycategory+'\\n')\n",
    "\n",
    "    #if ind==10: break\n",
    "newfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Even',\n",
       " 'Kolyma_River',\n",
       " 'Tianyuan',\n",
       " 'Surui',\n",
       " 'Papuan',\n",
       " 'Tubalar',\n",
       " 'Eskimo_Sireniki',\n",
       " 'Clovis',\n",
       " 'Zapotec',\n",
       " 'Bougainville',\n",
       " 'Kyrgyz',\n",
       " 'BoshanChineseNeolithic',\n",
       " 'Mebrak',\n",
       " 'Tlingit',\n",
       " 'Maori',\n",
       " 'Kusunda',\n",
       " 'Onge',\n",
       " 'Karitiana',\n",
       " 'Zongri',\n",
       " 'Chipewyan',\n",
       " 'Chokhopani1',\n",
       " 'Mayan',\n",
       " 'HDYM1',\n",
       " 'Chukchi',\n",
       " 'Linzi',\n",
       " 'Boisman_MN',\n",
       " 'Samdzong',\n",
       " 'Mixe',\n",
       " 'Eskimo_Naukan',\n",
       " 'Ulchi',\n",
       " 'Balikun',\n",
       " 'Daxi',\n",
       " 'Altaian',\n",
       " 'Piapoco',\n",
       " 'LiangDaoChineseNeolithic',\n",
       " 'Saqqaq',\n",
       " 'Pukagongma',\n",
       " 'Mongola',\n",
       " 'Sherpa',\n",
       " 'Longlin',\n",
       " 'Australian',\n",
       " 'Eskimo_Chaplin',\n",
       " 'Hawaiian',\n",
       " 'Dusun',\n",
       " 'Cree',\n",
       " 'Longlin_com',\n",
       " 'Xinyi',\n",
       " 'Bbdong',\n",
       " 'HQSDW',\n",
       " 'Aleut',\n",
       " 'Pima',\n",
       " 'Chane',\n",
       " 'Itelman',\n",
       " 'Igorot',\n",
       " 'Xinyi_other',\n",
       " 'Nahua',\n",
       " 'Yakut',\n",
       " 'Donghuigou',\n",
       " 'Quechua',\n",
       " 'Mansi']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(asn).difference(eas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
